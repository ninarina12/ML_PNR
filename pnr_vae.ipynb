{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a5fac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from pnr_utils import *\n",
    "from pnr_models import *\n",
    "\n",
    "seed = 12\n",
    "torch.set_default_dtype(torch.float64)\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "device = torch.device(\"cuda:6\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efa8e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to reload modules without restarting kernel (optional)\n",
    "from importlib import reload\n",
    "import sys\n",
    "reload(sys.modules['pnr_utils'])\n",
    "reload(sys.modules['pnr_models'])\n",
    "from pnr_utils import *\n",
    "from pnr_models import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b8bbde",
   "metadata": {},
   "source": [
    "### Load and process synthetic data\n",
    "\n",
    "- Input the **sample name** and the **set number** of the dataset generated by `pnr_generate.py` to locate the appropriate directories and read the metadata.\n",
    "\n",
    "\n",
    "- Load and process (apply noise, smoothing, and normalization to) spectra and identify the parameter names (y_header) and corresponding indices (y_ids) to use for supervised learning.\n",
    "\n",
    "\n",
    "- Standardize y-data (parameter values), perform train/valid/test split stratified by class, and convert data to torch tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f0e3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data properties\n",
    "sample_name = 'BiSe10_EuS5' #'CrO20_BiSbTe20'\n",
    "dataset = 0\n",
    "fit_roughness = False\n",
    "\n",
    "# get directories\n",
    "set_dir = 'results/' + sample_name + '/set_' + str(dataset)\n",
    "data_dir = set_dir + '/data'\n",
    "\n",
    "# parse metadata and experiment files\n",
    "layers, rho, M, N, q_min, q_max = parse_metadata(set_dir)\n",
    "q = 10*np.linspace(q_min, q_max, N)\n",
    "exp_names = next(os.walk('experiments/' + sample_name))[1]\n",
    "exp_names = [k for k in exp_names if '-' not in k]\n",
    "exp_names = [sample_name + '/' + exp_names[j] for j in np.argsort([int(i[:i.index('K')]) for i in exp_names])]\n",
    "\n",
    "print('set directory:', set_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67ac011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and process data\n",
    "x_data, x_orig, x_moms, y_data, y_columns, y_header, y_ids, y_labels, y_units = process_data(data_dir, sample_name,\n",
    "                                                                                             exp_names[0], q, seed,\n",
    "                                                                                             fit_roughness)\n",
    "\n",
    "# split data\n",
    "x_train, x_valid, x_test, y_train, y_valid, y_test = split_data(x_data, y_data, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6b522f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize data\n",
    "scaler = StandardScaler().fit(y_train[:,y_ids[:-1]])\n",
    "torch_scaler = TorchStandardScaler()\n",
    "torch_scaler.mean = torch.tensor(scaler.mean_).to(device)\n",
    "torch_scaler.std = torch.tensor(np.sqrt(scaler.var_)).to(device)\n",
    "\n",
    "y_train[:,np.array(y_ids[:-1])] = scaler.transform(y_train[:,y_ids[:-1]])\n",
    "y_valid[:,np.array(y_ids[:-1])] = scaler.transform(y_valid[:,y_ids[:-1]])\n",
    "y_test[:,np.array(y_ids[:-1])] = scaler.transform(y_test[:,y_ids[:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe40bf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to torch tensors\n",
    "x_train = torch.from_numpy(x_train).unsqueeze(1)\n",
    "x_valid = torch.from_numpy(x_valid).unsqueeze(1)\n",
    "x_test = torch.from_numpy(x_test).unsqueeze(1)\n",
    "y_train = torch.from_numpy(y_train)\n",
    "y_valid = torch.from_numpy(y_valid)\n",
    "y_test = torch.from_numpy(y_test)\n",
    "\n",
    "height = x_train.size()[2]\n",
    "width = x_train.size()[3]\n",
    "num_features = len(y_ids) - 1\n",
    "print('height:', height, 'width:', width, 'num_features:', num_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584ba314",
   "metadata": {},
   "source": [
    "### Define model\n",
    "\n",
    "- Input the **model name** (vae, cvae, rvae) for the model to train according to:\n",
    "    * vae: simple VAE with no classifier or regressors\n",
    "    * cvae: VAE + classifier\n",
    "    * rvae: CVAE + regressors for each parameter value\n",
    "\n",
    "\n",
    "- Input the **model number** to resume training (or to continue analysis without further fitting), or -1 to start a new fit.\n",
    "\n",
    "\n",
    "- Input the number of models (**reps**) to train in succession, and set the **batch size** and number of **epochs**.\n",
    "\n",
    "\n",
    "- Set **z_std_norm** to False if z_mean is presumed to match the parameter values, or True if presumed to be 0, and set the parameters defining the model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b0c064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model to train\n",
    "model_name = 'rvae'\n",
    "model_num = -1           # -1 to start a new fit, model number to resume or analyze\n",
    "\n",
    "# training parameters\n",
    "reps = 10\n",
    "batch_size = 256\n",
    "epochs = 60\n",
    "\n",
    "# model parameters\n",
    "z_std_norm = False       # True if z ~ N(0,1), False if z ~ N(mu,1), mu > 0\n",
    "kwargs = {\n",
    "    'hidden_dim': 512,\n",
    "    'latent_dim': 24,\n",
    "    'start_filters': 16,\n",
    "    'kernel_size': 7,\n",
    "    'pool_size': 4,\n",
    "    'num_conv': 2,\n",
    "    'num_dense': 5,\n",
    "    'slope': 0.3,\n",
    "    'drop': False,\n",
    "    'beta_1': 0.01,\n",
    "    'beta_2': 0.01\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0fe700",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print model architecture\n",
    "model, _, _ = init_model(model_name, height, width, num_features, kwargs, device, scaler=torch_scaler)\n",
    "print(model)\n",
    "\n",
    "print('number of parameters:', sum([p.numel() for p in model.parameters() if p.requires_grad]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed3cded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model directories\n",
    "model_prefix = '/' + model_name + '_'\n",
    "resume_fit = model_num >= 0\n",
    "\n",
    "if resume_fit:\n",
    "    # load args from saved model directory\n",
    "    model_dir = set_dir + model_prefix + str(model_num)\n",
    "    args = torch.load(model_dir + '/model_0/model.torch')['args']\n",
    "    start_epoch = args['epochs']\n",
    "    epochs = start_epoch + epochs\n",
    "    args['epochs'] = epochs\n",
    "    \n",
    "    kwargs = args['kwargs']\n",
    "    \n",
    "else:\n",
    "    # create new model directory\n",
    "    args = {}\n",
    "    dirs = next(os.walk(set_dir))[1]\n",
    "    for k in dirs:\n",
    "        if k.startswith('.'): dirs.remove(k)\n",
    "    dirs.remove('data')\n",
    "    if 'properties' in dirs: dirs.remove('properties')\n",
    "\n",
    "    if len(dirs):\n",
    "        idns = [int(d.split('_')[-1]) for d in dirs]\n",
    "        idn = max(idns) + 1\n",
    "        args['model_num'] = idn\n",
    "        model_dir = set_dir + model_prefix + str(idn)\n",
    "    else:\n",
    "        args['model_num'] = 0\n",
    "        model_dir = set_dir + model_prefix + '0'\n",
    "\n",
    "    os.makedirs(model_dir)\n",
    "    start_epoch = 0\n",
    "    \n",
    "    # save arguments\n",
    "    args['batch_size'] = batch_size\n",
    "    args['reps'] = reps\n",
    "    args['epochs'] = epochs\n",
    "    args['z_std_norm'] = z_std_norm\n",
    "    args['kwargs'] = kwargs.copy()\n",
    "    \n",
    "meta = json.dumps(args, sort_keys=True, indent=2)\n",
    "with open(model_dir + '/args.txt', 'w') as f:\n",
    "    f.write(meta)\n",
    "\n",
    "print('model directory:', model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eae9f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure data loaders\n",
    "data_train = TensorDataset(x_train, y_train)\n",
    "data_valid = TensorDataset(x_valid, y_valid)\n",
    "data_test = TensorDataset(x_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(data_train, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(data_valid, batch_size=batch_size)\n",
    "test_loader = DataLoader(data_test, batch_size=batch_size)\n",
    "\n",
    "d_sets = ['train', 'valid', 'test']\n",
    "data_loaders = dict(zip(d_sets, [DataLoader(data_train, batch_size=batch_size), valid_loader, test_loader]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769609e2",
   "metadata": {},
   "source": [
    "### Train model\n",
    "\n",
    "- Train reps number of models in succession."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6837981",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for r in range(reps):\n",
    "    image_dir = model_dir + '/model_' + str(r)\n",
    "    if not os.path.exists(image_dir): os.makedirs(image_dir)\n",
    "\n",
    "    model, opt, metric_keys = init_model(model_name, height, width, num_features, kwargs, device, scaler=torch_scaler)\n",
    "\n",
    "    print('====== repetition:', r)\n",
    "\n",
    "    if resume_fit:\n",
    "        model.load_state_dict(torch.load(image_dir + '/model.torch')['state'])\n",
    "        opt.load_state_dict(torch.load(image_dir + '/model.torch')['optimizer'])\n",
    "        dynamics = torch.load(image_dir + '/model.torch')['dynamics']\n",
    "    else: dynamics = []\n",
    "\n",
    "    for epoch in range(start_epoch + 1, epochs + 1):\n",
    "        train_metrics = train(epoch, model, opt, metric_keys, train_loader, device, model_name, z_std_norm, y_ids) \n",
    "        valid_metrics = evaluate(epoch, model, metric_keys, valid_loader, device, model_name, z_std_norm, y_ids)\n",
    "        dynamics.append({\n",
    "            'epoch': epoch,\n",
    "            'train': train_metrics,\n",
    "            'valid': valid_metrics\n",
    "        })\n",
    "\n",
    "    results = {\n",
    "        'args': args,\n",
    "        'dynamics': dynamics,\n",
    "        'state': model.state_dict(),\n",
    "        'optimizer': opt.state_dict()\n",
    "    }\n",
    "\n",
    "    # save data and metadata to .torch dictionary\n",
    "    with open(image_dir + '/model.torch', 'wb') as f:\n",
    "        torch.save(results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029203fe",
   "metadata": {},
   "source": [
    "### Evaluate a representative model\n",
    "\n",
    "- Input the **repetition** to load the corresponding trained model.\n",
    "\n",
    "\n",
    "- Load and process the experimental data.\n",
    "\n",
    "\n",
    "- Plot the training history.\n",
    "\n",
    "\n",
    "- Make predictions on all synthetic and experimental data.\n",
    "\n",
    "\n",
    "- Plot example reconstructions of synthetic data in each error quartile, and reconstructions of experimental data.\n",
    "\n",
    "\n",
    "- Visualize the latent space according to y-values along 2 dimensions.\n",
    "\n",
    "\n",
    "- Plot performance of regressors, if present.\n",
    "\n",
    "\n",
    "- Find the optimal threshold for classifier and plot classifier performance, if present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a808ac03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# repetition to evaluate\n",
    "r = 0\n",
    "image_dir = model_dir + '/model_' + str(r)\n",
    "model, _, _ = init_model(model_name, height, width, num_features, kwargs, device, scaler=torch_scaler)\n",
    "model.load_state_dict(torch.load(image_dir + '/model.torch')['state'])\n",
    "model.eval()\n",
    "\n",
    "# process experiment\n",
    "x_exp = process_exp(exp_names, q, x_moms)\n",
    "x_exp = torch.from_numpy(x_exp).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1818473",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot training history\n",
    "dynamics = torch.load(image_dir + '/model.torch')['dynamics']\n",
    "plot_history(image_dir, dynamics, logscale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bf76ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on synthetic data\n",
    "df = get_predictions(model, data_loaders, d_sets, device, height, width, num_features, kwargs, model_name, z_std_norm,\n",
    "                     y_ids, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c7396e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on experimental data\n",
    "df_exp = get_predictions_exp(model, x_exp, exp_names, device, height, width, num_features, kwargs, model_name,\n",
    "                             z_std_norm, y_ids, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ef2ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exp[['set', 'y_pred']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc6a4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print predictions of i_th experiment\n",
    "i = 0\n",
    "print('experiment:', exp_names[i])\n",
    "if model_name == 'rvae':\n",
    "    dict_exp = dict(zip(y_header + ['class'], df_exp.iloc[i]['y_pred']))\n",
    "    print(dict_exp)\n",
    "    \n",
    "elif model_name == 'cvae':\n",
    "    dict_exp = dict(zip(y_header, df_exp.iloc[i]['z'][:len(y_header)-1]))\n",
    "    dict_exp['class_prox'] = df_exp.iloc[i]['y_pred'][0]\n",
    "    print(dict_exp)\n",
    "\n",
    "else:\n",
    "    if not z_std_norm:\n",
    "        dict_exp = dict(zip(y_header, df_exp.iloc[i]['z'][:len(y_header)-1]))\n",
    "        print(dict_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f036c173",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot example reconstructions\n",
    "plot_decoded(image_dir, np.stack(df.loc[df['set']=='test', 'x_pred'].values),\n",
    "             np.stack(df.loc[df['set']=='test', 'x_true'].values),\n",
    "             np.stack(df.loc[df['set']=='test', 'x_mse'].values), 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a758bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to reload modules without restarting kernel (optional)\n",
    "from importlib import reload\n",
    "import sys\n",
    "reload(sys.modules['pnr_utils'])\n",
    "reload(sys.modules['pnr_models'])\n",
    "from pnr_utils import *\n",
    "from pnr_models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001a6028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot reconstructed experiment\n",
    "plot_decoded_exp(image_dir, np.stack(df_exp['x_pred'].values), exp_names, q, x_moms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c88f5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize separability of latent space\n",
    "plot_latent_representation(image_dir, np.stack(df.loc[df['set']=='test', 'z'].values),\n",
    "                           np.stack(df.loc[df['set']=='test', 'y_true'].values),\n",
    "                           y_ids, y_labels, y_units, 'encoded_test', np.stack(df_exp['z'].values), exp_names, mode=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f7939c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot regressor performance\n",
    "if model_name == 'rvae':\n",
    "    plot_predicted(image_dir, np.stack(df.loc[df['set']=='test', 'y_pred'].values),\n",
    "               np.stack(df.loc[df['set']=='test', 'y_true'].values),\n",
    "               np.stack(df.loc[df['set']=='test', 'y_err'].values), y_ids, y_labels, y_units)\n",
    "\n",
    "else:\n",
    "    if not z_std_norm:\n",
    "        plot_predicted(image_dir, np.stack(df.loc[df['set']=='test', 'z'].values),\n",
    "                       np.stack(df.loc[df['set']=='test', 'y_true'].values),\n",
    "                       np.stack(df.loc[df['set']=='test', 'z_mse'].values), y_ids, y_labels, y_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7170911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot regressor performance per property\n",
    "if model_name == 'rvae':\n",
    "    y_name = 'magn_prox'\n",
    "    plot_predicted_property(image_dir, np.stack(df.loc[df['set']=='test', 'y_pred'].values),\n",
    "                            np.stack(df.loc[df['set']=='test', 'y_true'].values),\n",
    "                            np.stack(df.loc[df['set']=='test', 'y_err'].values), y_name,\n",
    "                            y_header, y_ids, y_labels, y_units)\n",
    "\n",
    "else:\n",
    "    if not z_std_norm:\n",
    "        plot_predicted(image_dir, np.stack(df.loc[df['set']=='test', 'z'].values),\n",
    "                       np.stack(df.loc[df['set']=='test', 'y_true'].values),\n",
    "                       np.stack(df.loc[df['set']=='test', 'z_mse'].values), y_ids, y_labels, y_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c8d2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dict(zip(y_header, y_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5599cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find optimal threshold and plot classifier performance\n",
    "if model_name == 'cvae':\n",
    "    fpr, tpr, roc_auc, th = get_roc(df, d_sets)\n",
    "    tpr0, fpr0, th = get_optimal_threshold(fpr[1], tpr[1], th[1])\n",
    "\n",
    "    plot_roc(image_dir, fpr, tpr, roc_auc, [tpr0, fpr0, th])\n",
    "    plot_precision_recall_f1(image_dir, df, d_sets, th)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985ac9e8",
   "metadata": {},
   "source": [
    "### Evaluate all models\n",
    "\n",
    "- Compile the training history and experiment predictions on all model repetitions.\n",
    "\n",
    "\n",
    "- Plot the training history statistics.\n",
    "\n",
    "\n",
    "- Plot classification statistics on experimental data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3167de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on all models to compute statistics\n",
    "dynamics = []\n",
    "#for r in range(reps):\n",
    "for r in range(reps):\n",
    "    image_dir = model_dir + '/model_' + str(r)\n",
    "    model, _, _ = init_model(model_name, height, width, num_features, kwargs, device, scaler=torch_scaler)\n",
    "    model.load_state_dict(torch.load(image_dir + '/model.torch')['state'])\n",
    "    \n",
    "    # plot training history\n",
    "    dynamics += [torch.load(image_dir + '/model.torch')['dynamics']]\n",
    "    \n",
    "    # get optimal threshold\n",
    "    if model_name == 'cvae':\n",
    "        \n",
    "        # predict on synthetic data\n",
    "        df = get_predictions(model, data_loaders, d_sets, device, height, width, num_features, kwargs, model_name,\n",
    "                             z_std_norm, y_ids, scaler)\n",
    "    \n",
    "        fpr, tpr, _, th = get_roc(df, d_sets)\n",
    "        _, _, th = get_optimal_threshold(fpr[1], tpr[1], th[1])\n",
    "        \n",
    "    # predict on experimental data\n",
    "    if r > 0:\n",
    "        df = get_predictions_exp(model, x_exp, exp_names, device, height, width, num_features, kwargs, model_name,\n",
    "                                 z_std_norm, y_ids, scaler)\n",
    "        df['model'] = r\n",
    "        if model_name == 'cvae': df['th'] = th\n",
    "        df_exp = df_exp.append(df, ignore_index=True)\n",
    "        \n",
    "    else:\n",
    "        df_exp = get_predictions_exp(model, x_exp, exp_names, device, height, width, num_features, kwargs, model_name,\n",
    "                                     z_std_norm, y_ids, scaler)\n",
    "        df_exp['model'] = r\n",
    "        if model_name == 'cvae': df_exp['th'] = th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1445f5ed",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot training history statistics\n",
    "plot_history_statistics(model_dir, dynamics, logscale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bed6612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot class statistics on experimental sample\n",
    "if model_name == 'cvae':\n",
    "    plot_class_exp_statistics(model_dir, df_exp, reps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd33b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not z_std_norm:\n",
    "    plot_exp_statistics(model_dir, df_exp, reps, 'magn_prox', y_header, y_labels, y_units, y_th=1)\n",
    "    plot_exp_statistics(model_dir, df_exp, reps, 'd_prox', y_header, y_labels, y_units, y_th=1)\n",
    "    plot_exp_statistics(model_dir, df_exp, reps, 'd_TI', y_header, y_labels, y_units)\n",
    "    plot_exp_statistics(model_dir, df_exp, reps, 'magn_FM', y_header, y_labels, y_units, y_th=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5791bff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
