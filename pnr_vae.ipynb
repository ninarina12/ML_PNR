{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b867c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from pnr_utils import *\n",
    "from pnr_models import *\n",
    "from plot_sld import plot_SLD\n",
    "\n",
    "seed = 12\n",
    "torch.set_default_dtype(torch.float64)\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "device = torch.device(\"cuda:7\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d2c540",
   "metadata": {},
   "source": [
    "### Load and process synthetic data\n",
    "\n",
    "- Input the **sample name** and the **set number** of the dataset generated by `pnr_generate.py` to locate the appropriate directories and read the metadata.\n",
    "\n",
    "\n",
    "- Load and process (apply noise, smoothing, and normalization to) spectra and identify the parameter names (y_header) and corresponding indices (y_ids) to use for supervised learning.\n",
    "\n",
    "\n",
    "- Standardize y-data (parameter values), perform train/valid/test split stratified by class, and convert data to torch tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4795fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data properties\n",
    "sample_name = 'BiSe10_EuS5' #'CrO20_BiSbTe20' \n",
    "dataset = 0\n",
    "fit_roughness = False\n",
    "\n",
    "# get directories\n",
    "set_dir = 'results/' + sample_name + '/set_' + str(dataset)\n",
    "data_dir = set_dir + '/data'\n",
    "\n",
    "# parse metadata and experiment files\n",
    "layers, rho, M, N, q_min, q_max = parse_metadata(set_dir)\n",
    "q = 10*np.linspace(q_min, q_max, N)\n",
    "exp_names = next(os.walk('experiments/' + sample_name))[1]\n",
    "exp_names = [k for k in exp_names if '-' not in k]\n",
    "exp_names = [sample_name + '/' + exp_names[j] for j in np.argsort([int(i[:i.index('K')]) for i in exp_names])]\n",
    "\n",
    "print('set directory:', set_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81abf8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and process data\n",
    "x_data, x_orig, x_moms, y_data, y_columns, y_header, \\\n",
    "y_ids, y_labels, y_units, y_units_ = process_data(data_dir, sample_name, exp_names[0], q, seed, fit_roughness)\n",
    "\n",
    "# split data\n",
    "x_train, x_valid, x_test, y_train, y_valid, y_test = split_data(x_data, y_data, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb9d3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize data\n",
    "scaler = StandardScaler().fit(y_train[:,y_ids[:-1]])\n",
    "torch_scaler = TorchStandardScaler()\n",
    "torch_scaler.mean = torch.tensor(scaler.mean_).to(device)\n",
    "torch_scaler.std = torch.tensor(np.sqrt(scaler.var_)).to(device)\n",
    "\n",
    "y_train[:,np.array(y_ids[:-1])] = scaler.transform(y_train[:,y_ids[:-1]])\n",
    "y_valid[:,np.array(y_ids[:-1])] = scaler.transform(y_valid[:,y_ids[:-1]])\n",
    "y_test[:,np.array(y_ids[:-1])] = scaler.transform(y_test[:,y_ids[:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7290d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to torch tensors\n",
    "x_train = torch.from_numpy(x_train).unsqueeze(1)\n",
    "x_valid = torch.from_numpy(x_valid).unsqueeze(1)\n",
    "x_test = torch.from_numpy(x_test).unsqueeze(1)\n",
    "y_train = torch.from_numpy(y_train)\n",
    "y_valid = torch.from_numpy(y_valid)\n",
    "y_test = torch.from_numpy(y_test)\n",
    "\n",
    "height = x_train.size()[2]\n",
    "width = x_train.size()[3]\n",
    "num_features = len(y_ids) - 1\n",
    "prox_features = [k for k, v in enumerate(y_header) if 'prox' in v][:-1]\n",
    "print('height:', height, 'width:', width, 'num_features:', num_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ef02be",
   "metadata": {},
   "source": [
    "### Define model\n",
    "\n",
    "- Input the **model name** (vae, cvae, rvae, rcvae) for the model to train according to:\n",
    "    * vae: simple VAE with no classifier or regressors\n",
    "    * cvae: VAE + classifier\n",
    "    * rvae: VAE + regressors for each parameter value\n",
    "    * rcvae: CVAE + regressors for each parameter value\n",
    "\n",
    "\n",
    "- Input the **model number** to resume training (or to continue analysis without further fitting), or -1 to start a new fit.\n",
    "\n",
    "\n",
    "- Input the number of models (**reps**) to train in succession, and set the **batch size** and number of **epochs**.\n",
    "\n",
    "\n",
    "- Set **z_std_norm** to False if z_mean is presumed to match the parameter values, or True if presumed to be 0, and set the parameters defining the model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48c218e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model to train\n",
    "model_name = 'rvae'\n",
    "model_num = -1            # -1 to start a new fit, model number to resume or analyze\n",
    "\n",
    "# training parameters\n",
    "reps = 1\n",
    "batch_size = 256\n",
    "epochs = 100\n",
    "\n",
    "# model parameters\n",
    "z_std_norm = False       # True if z ~ N(0,1), False if z ~ N(mu,1), mu > 0\n",
    "kwargs = {\n",
    "    'hidden_dim': 512,\n",
    "    'latent_dim': 24,\n",
    "    'start_filters': 16,\n",
    "    'kernel_size': 7,\n",
    "    'pool_size': 4,\n",
    "    'num_conv': 2,\n",
    "    'num_dense': 5,\n",
    "    'slope': 0.3,\n",
    "    'drop': False,\n",
    "    'beta_1': 0.01,\n",
    "    'beta_2': 0.01\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e34a43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print model architecture\n",
    "model, _, _ = init_model(model_name, height, width, num_features, kwargs, device,\n",
    "                         prox_features=prox_features, scaler=torch_scaler)\n",
    "print(model)\n",
    "\n",
    "print('number of parameters:', sum([p.numel() for p in model.parameters() if p.requires_grad]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb5d967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model directories\n",
    "model_prefix = '/' + model_name + '_'\n",
    "resume_fit = model_num >= 0\n",
    "\n",
    "if resume_fit:\n",
    "    # load args from saved model directory\n",
    "    model_dir = set_dir + model_prefix + str(model_num)\n",
    "    args = torch.load(model_dir + '/model_0/model.torch', map_location='cpu')['args']\n",
    "    start_epoch = args['epochs']\n",
    "    epochs = start_epoch + epochs\n",
    "    args['epochs'] = epochs\n",
    "    \n",
    "    kwargs = args['kwargs']\n",
    "    \n",
    "else:\n",
    "    # create new model directory\n",
    "    args = {}\n",
    "    dirs = next(os.walk(set_dir))[1]\n",
    "    for k in dirs:\n",
    "        if k.startswith('.'): dirs.remove(k)\n",
    "    dirs.remove('data')\n",
    "    if 'properties' in dirs: dirs.remove('properties')\n",
    "\n",
    "    if len(dirs):\n",
    "        idns = [int(d.split('_')[-1]) for d in dirs]\n",
    "        idn = max(idns) + 1\n",
    "        args['model_num'] = idn\n",
    "        model_dir = set_dir + model_prefix + str(idn)\n",
    "    else:\n",
    "        args['model_num'] = 0\n",
    "        model_dir = set_dir + model_prefix + '0'\n",
    "\n",
    "    os.makedirs(model_dir)\n",
    "    start_epoch = 0\n",
    "    \n",
    "    # save arguments\n",
    "    args['batch_size'] = batch_size\n",
    "    args['reps'] = reps\n",
    "    args['epochs'] = epochs\n",
    "    args['z_std_norm'] = z_std_norm\n",
    "    args['kwargs'] = kwargs.copy()\n",
    "    \n",
    "meta = json.dumps(args, sort_keys=True, indent=2)\n",
    "with open(model_dir + '/args.txt', 'w') as f:\n",
    "    f.write(meta)\n",
    "\n",
    "print('model directory:', model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95177dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure data loaders\n",
    "data_train = TensorDataset(x_train, y_train)\n",
    "data_valid = TensorDataset(x_valid, y_valid)\n",
    "data_test = TensorDataset(x_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(data_train, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(data_valid, batch_size=batch_size)\n",
    "test_loader = DataLoader(data_test, batch_size=batch_size)\n",
    "\n",
    "d_sets = ['train', 'valid', 'test']\n",
    "data_loaders = dict(zip(d_sets, [DataLoader(data_train, batch_size=batch_size), valid_loader, test_loader]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc71055",
   "metadata": {},
   "source": [
    "### Train model\n",
    "\n",
    "- Train reps number of models in succession."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedc86fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for r in range(reps):\n",
    "    image_dir = model_dir + '/model_' + str(r)\n",
    "    if not os.path.exists(image_dir): os.makedirs(image_dir)\n",
    "\n",
    "    model, opt, metric_keys = init_model(model_name, height, width, num_features, kwargs, device,\n",
    "                                         prox_features=prox_features, scaler=torch_scaler)\n",
    "\n",
    "    print('====== repetition:', r)\n",
    "\n",
    "    if resume_fit:\n",
    "        model.load_state_dict(torch.load(image_dir + '/model.torch', map_location=device)['state'])\n",
    "        opt.load_state_dict(torch.load(image_dir + '/model.torch', map_location=device)['optimizer'])\n",
    "        dynamics = torch.load(image_dir + '/model.torch', map_location='cpu')['dynamics']\n",
    "    else: dynamics = []\n",
    "\n",
    "    for epoch in range(start_epoch + 1, epochs + 1):\n",
    "        train_metrics = train(epoch, model, opt, metric_keys, train_loader, device, model_name, z_std_norm, y_ids) \n",
    "        valid_metrics = evaluate(epoch, model, metric_keys, valid_loader, device, model_name, z_std_norm, y_ids)\n",
    "        dynamics.append({\n",
    "            'epoch': epoch,\n",
    "            'train': train_metrics,\n",
    "            'valid': valid_metrics\n",
    "        })\n",
    "\n",
    "    results = {\n",
    "        'args': args,\n",
    "        'dynamics': dynamics,\n",
    "        'state': model.state_dict(),\n",
    "        'optimizer': opt.state_dict()\n",
    "    }\n",
    "\n",
    "    # save data and metadata to .torch dictionary\n",
    "    with open(image_dir + '/model.torch', 'wb') as f:\n",
    "        torch.save(results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a3101c",
   "metadata": {},
   "source": [
    "### Evaluate a representative model\n",
    "\n",
    "- Input the **repetition** to load the corresponding trained model.\n",
    "\n",
    "\n",
    "- Load and process the experimental data.\n",
    "\n",
    "\n",
    "- Plot the training history.\n",
    "\n",
    "\n",
    "- Make predictions on all synthetic and experimental data.\n",
    "\n",
    "\n",
    "- Plot example reconstructions of synthetic data in each error quartile, and reconstructions of experimental data.\n",
    "\n",
    "\n",
    "- Visualize the latent space along 2 dimensions.\n",
    "\n",
    "\n",
    "- Plot performance of regressors, if present.\n",
    "\n",
    "\n",
    "- Find the optimal threshold for classifier and plot classifier performance, if present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9133d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# repetition to evaluate\n",
    "r = 0\n",
    "image_dir = model_dir + '/model_' + str(r)\n",
    "model, _, _ = init_model(model_name, height, width, num_features, kwargs, device,\n",
    "                         prox_features=prox_features, scaler=torch_scaler)\n",
    "model.load_state_dict(torch.load(image_dir + '/model.torch', map_location=device)['state'])\n",
    "model.eval()\n",
    "\n",
    "# process experiment\n",
    "x_exp = process_exp(exp_names, q, x_moms)\n",
    "x_exp = torch.from_numpy(x_exp).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a809bcc1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot training history\n",
    "dynamics = torch.load(image_dir + '/model.torch', map_location='cpu')['dynamics']\n",
    "plot_history(image_dir, dynamics, logscale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead74734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on synthetic data\n",
    "df = get_predictions(model, data_loaders, d_sets, device, height, width, num_features, kwargs, model_name, z_std_norm,\n",
    "                     y_ids, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8b8fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on experimental data\n",
    "df_exp = get_predictions_exp(model, x_exp, exp_names, device, height, width, num_features, kwargs, model_name,\n",
    "                             z_std_norm, y_ids, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752b9bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert magnetization units to emu/cm^3\n",
    "df['y_true_'] = df['y_true'].map(lambda x: convert_magn(x, y_columns))\n",
    "df['y_pred_'] = df['y_pred'].map(lambda x: convert_magn(x, y_header))\n",
    "df_exp['y_pred_'] = df_exp['y_pred'].map(lambda x: convert_magn(x, y_header))\n",
    "\n",
    "# convert density units to g/cm^3\n",
    "m = [M[0]] + drop_duplicates_list(M[1:])\n",
    "df['y_true_'] = df['y_true_'].map(lambda x: convert_dens(x, m))\n",
    "df['y_pred_'] = df['y_pred_'].map(lambda x: convert_dens(x, m))\n",
    "df_exp['y_pred_'] = df_exp['y_pred_'].map(lambda x: convert_dens(x, m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a537ae7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = 0\n",
    "for i in range(len(df_exp)):\n",
    "    y_pred = df_exp.iloc[i]['y_pred']\n",
    "    tag = df_exp.iloc[i]['set']\n",
    "    if i == 0:\n",
    "        y_lims = plot_SLD(image_dir, sample_name, y_pred, y_header, tag, scale=scale)\n",
    "    else:\n",
    "        plot_SLD(image_dir, sample_name, y_pred, y_header, tag, scale=scale, y_lims=y_lims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa85b1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print predictions of i_th experiment\n",
    "i = 0\n",
    "print('experiment:', exp_names[i])\n",
    "if (model_name == 'rcvae') or (model_name == 'rvae'):\n",
    "    dict_exp = dict(zip(y_header, df_exp.iloc[i]['y_pred_']))\n",
    "    print(dict_exp)\n",
    "    \n",
    "elif model_name == 'cvae':\n",
    "    dict_exp = dict(zip(y_header, df_exp.iloc[i]['z'][:len(y_header)-1]))\n",
    "    dict_exp['class_prox'] = df_exp.iloc[i]['y_pred_'][0]\n",
    "    print(dict_exp)\n",
    "\n",
    "else:\n",
    "    if not z_std_norm:\n",
    "        dict_exp = dict(zip(y_header, df_exp.iloc[i]['z'][:len(y_header)-1]))\n",
    "        print(dict_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f9a815",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot example reconstructions\n",
    "plot_decoded(image_dir, np.stack(df.loc[df['set']=='test', 'x_pred'].values),\n",
    "             np.stack(df.loc[df['set']=='test', 'x_true'].values),\n",
    "             np.stack(df.loc[df['set']=='test', 'x_mse'].values), 'test',\n",
    "             df_exp['x_mse'].values, exp_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279bf75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot reconstructed experiment\n",
    "plot_decoded_exp(image_dir, np.stack(df_exp['x_pred'].values), exp_names, q, x_moms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded33d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize separability of latent space\n",
    "plot_latent_representation(image_dir, np.stack(df.loc[df['set']=='test', 'z'].values),\n",
    "                           np.stack(df.loc[df['set']=='test', 'y_true_'].values),\n",
    "                           y_ids, y_labels, y_units_, 'encoded_test', np.stack(df_exp['z'].values), exp_names, mode=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fec9280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot histogram of regressor predictions\n",
    "if (model_name == 'rcvae') or (model_name == 'rvae'):\n",
    "    plot_predicted(image_dir, np.stack(df.loc[df['set']=='test', 'y_pred_'].values),\n",
    "                   np.stack(df.loc[df['set']=='test', 'y_true_'].values), y_ids, y_labels, y_units_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03bb5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot regressor performance per property\n",
    "if (model_name == 'rcvae') or (model_name == 'rvae'):\n",
    "    for y_name in y_header[:-1]:\n",
    "        if y_name in ['d_prox', 'magn_prox']: qs = (0.25, 0.5, 0.75, 0.95)\n",
    "        else: qs = (0.5, 0.75, 0.95)\n",
    "        plot_predicted_property(image_dir, np.stack(df.loc[df['set']=='test', 'y_pred'].values),\n",
    "                                np.stack(df.loc[df['set']=='test', 'y_true'].values),\n",
    "                                np.stack(df.loc[df['set']=='test', 'y_err'].values), y_name,\n",
    "                                y_header, y_ids, y_labels, y_units, qs=qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72514972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find optimal threshold and plot classifier performance\n",
    "if 'cvae' in model_name:\n",
    "    fpr, tpr, roc_auc, th = get_roc(df, d_sets)\n",
    "    tpr0, fpr0, th = get_optimal_threshold(fpr[1], tpr[1], th[1])\n",
    "\n",
    "    plot_roc(image_dir, fpr, tpr, roc_auc, [tpr0, fpr0, th])\n",
    "    plot_precision_recall_f1(image_dir, df, d_sets, th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4aed6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find optimal threshold for proximity parameters and plot confusion matrices\n",
    "if (model_name == 'rcvae') or (model_name == 'rvae'):\n",
    "    for y_name in ['d_prox', 'magn_prox']:\n",
    "        fpr, tpr, y_th = get_roc_prox(df, y_header, y_name)\n",
    "        _, _, y_th = get_optimal_threshold(fpr, tpr, y_th)\n",
    "        plot_confusion_matrix(image_dir, df, y_header, y_name, y_th)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a7adc2",
   "metadata": {},
   "source": [
    "### Evaluate all models\n",
    "\n",
    "- Compile the training history and experiment predictions on all model repetitions.\n",
    "\n",
    "\n",
    "- Plot the training history statistics.\n",
    "\n",
    "\n",
    "- Plot classification statistics on experimental data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175bcb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on all models to compute statistics\n",
    "dynamics = []\n",
    "m = [M[0]] + drop_duplicates_list(M[1:])\n",
    "for r in range(reps):\n",
    "    image_dir = model_dir + '/model_' + str(r)\n",
    "    model, _, _ = init_model(model_name, height, width, num_features, kwargs, device,\n",
    "                             prox_features=prox_features, scaler=torch_scaler)\n",
    "    model.load_state_dict(torch.load(image_dir + '/model.torch', map_location=device)['state'])\n",
    "    \n",
    "    # plot training history\n",
    "    dynamics += [torch.load(image_dir + '/model.torch', map_location='cpu')['dynamics']]\n",
    "    \n",
    "    # get optimal threshold\n",
    "    if 'cvae' in model_name:\n",
    "        # predict on synthetic data\n",
    "        df = get_predictions(model, data_loaders, ['valid'], device, height, width, num_features, kwargs, model_name,\n",
    "                             z_std_norm, y_ids, scaler)\n",
    "    \n",
    "        fpr, tpr, _, th = get_roc(df, ['valid'])\n",
    "        _, _, th = get_optimal_threshold(fpr[0], tpr[0], th[0])\n",
    "        \n",
    "        if model_name == 'rcvae':\n",
    "            # convert magnetization units to emu/cm^3\n",
    "            df['y_true_'] = df['y_true'].map(lambda x: convert_magn(x, y_columns))\n",
    "            df['y_pred_'] = df['y_pred'].map(lambda x: convert_magn(x, y_header))\n",
    "\n",
    "            # convert density units to g/cm^3\n",
    "            df['y_true_'] = df['y_true_'].map(lambda x: convert_dens(x, m))\n",
    "            df['y_pred_'] = df['y_pred_'].map(lambda x: convert_dens(x, m))\n",
    "        \n",
    "            # find optimal threshold for proximity parameters\n",
    "            d_fpr, d_tpr, d_th = get_roc_prox(df, y_header, 'd_prox')\n",
    "            _, _, d_th = get_optimal_threshold(d_fpr, d_tpr, d_th)\n",
    "\n",
    "            m_fpr, m_tpr, m_th = get_roc_prox(df, y_header, 'magn_prox')\n",
    "            _, _, m_th = get_optimal_threshold(m_fpr, m_tpr, m_th)\n",
    "        \n",
    "    elif model_name == 'rvae':\n",
    "        # predict on synthetic data\n",
    "        df = get_predictions(model, data_loaders, ['valid'], device, height, width, num_features, kwargs, model_name,\n",
    "                             z_std_norm, y_ids, scaler)\n",
    "        \n",
    "        # convert magnetization units to emu/cm^3\n",
    "        df['y_true_'] = df['y_true'].map(lambda x: convert_magn(x, y_columns))\n",
    "        df['y_pred_'] = df['y_pred'].map(lambda x: convert_magn(x, y_header))\n",
    "\n",
    "        # convert density units to g/cm^3\n",
    "        df['y_true_'] = df['y_true_'].map(lambda x: convert_dens(x, m))\n",
    "        df['y_pred_'] = df['y_pred_'].map(lambda x: convert_dens(x, m))\n",
    "\n",
    "        # find optimal threshold for proximity parameters\n",
    "        d_fpr, d_tpr, d_th = get_roc_prox(df, y_header, 'd_prox')\n",
    "        _, _, d_th = get_optimal_threshold(d_fpr, d_tpr, d_th)\n",
    "\n",
    "        m_fpr, m_tpr, m_th = get_roc_prox(df, y_header, 'magn_prox')\n",
    "        _, _, m_th = get_optimal_threshold(m_fpr, m_tpr, m_th)\n",
    "    \n",
    "    # predict on experimental data\n",
    "    if r > 0:\n",
    "        df = get_predictions_exp(model, x_exp, exp_names, device, height, width, num_features, kwargs, model_name,\n",
    "                                 z_std_norm, y_ids, scaler)\n",
    "        df['model'] = r\n",
    "        if 'cvae' in model_name:\n",
    "            df['th'] = th\n",
    "        if (model_name == 'rcvae') or (model_name == 'rvae'):\n",
    "            df['d_th'] = d_th\n",
    "            df['m_th'] = m_th\n",
    "            df['y_pred_'] = df['y_pred'].map(lambda x: convert_magn(x, y_header))\n",
    "            df['y_pred_'] = df['y_pred_'].map(lambda x: convert_dens(x, m))\n",
    "        df_exp = df_exp.append(df, ignore_index=True)\n",
    "        \n",
    "    else:\n",
    "        df_exp = get_predictions_exp(model, x_exp, exp_names, device, height, width, num_features, kwargs, model_name,\n",
    "                                     z_std_norm, y_ids, scaler)\n",
    "        df_exp['model'] = r\n",
    "        if 'cvae' in model_name:\n",
    "            df_exp['th'] = th\n",
    "        if (model_name == 'rcvae') or (model_name == 'rvae'):\n",
    "            df_exp['d_th'] = d_th\n",
    "            df_exp['m_th'] = m_th\n",
    "            df_exp['y_pred_'] = df_exp['y_pred'].map(lambda x: convert_magn(x, y_header))\n",
    "            df_exp['y_pred_'] = df_exp['y_pred_'].map(lambda x: convert_dens(x, m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9813d15a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot training history statistics\n",
    "plot_history_statistics(model_dir, dynamics, logscale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e572f22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (model_name == 'rcvae') or (model_name == 'rvae'):\n",
    "    y_test_orig = scaler.inverse_transform(y_test[:,y_ids[:-1]])\n",
    "    y_test_ = y_test_orig.copy()\n",
    "    for i, v in enumerate(y_test_orig):\n",
    "        y_test_[i,:] = convert_magn(v, y_header)\n",
    "        y_test_[i,:] = convert_dens(y_test_[i,:], m)\n",
    "        \n",
    "    y_min = y_test_.min(axis=0)\n",
    "    y_max = y_test_.max(axis=0)\n",
    "    for i, y_name in enumerate(y_header[:-1]):\n",
    "        if y_name in ['d_prox', 'd_iAFM']:\n",
    "            y_th = df_exp['d_th'].mean()\n",
    "        elif 'magn' in y_name:\n",
    "            y_th = df_exp['m_th'].mean()\n",
    "        else: y_th = None\n",
    "        ylims = [y_min[i], y_max[i]]\n",
    "        plot_exp_statistics(model_dir, df_exp, reps, y_name, y_header, y_labels, y_units_, y_th=y_th, y_lims=ylims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4d6be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot class statistics on experimental sample\n",
    "if 'cvae' in model_name:\n",
    "    plot_class_exp_statistics(model_dir, df_exp, reps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3d6d36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
