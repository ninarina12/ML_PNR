{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b3f0f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from pnr_utils import *\n",
    "from pnr_models import *\n",
    "\n",
    "seed = 12\n",
    "torch.set_default_dtype(torch.float64)\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f58e7ab",
   "metadata": {},
   "source": [
    "### Load and process synthetic data\n",
    "\n",
    "- Input the **sample name** and the **set number** of the dataset generated by `pnr_generate.py` to locate the appropriate directories and read the metadata.\n",
    "\n",
    "\n",
    "- Load and process (apply noise, smoothing, and normalization to) spectra and identify the parameter names (y_header) and corresponding indices (y_ids) to use for supervised learning.\n",
    "\n",
    "\n",
    "- Standardize y-data (parameter values), perform train/valid/test split stratified by class, and convert data to torch tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84c955a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set directory: results/BiSe10_EuS5/set_0\n"
     ]
    }
   ],
   "source": [
    "# set data properties\n",
    "sample_name = 'BiSe10_EuS5' #CrO20_BiSbTe20\n",
    "dataset = 0\n",
    "\n",
    "# get directories\n",
    "set_dir = 'results/' + sample_name + '/set_' + str(dataset)\n",
    "data_dir = set_dir + '/data'\n",
    "\n",
    "# parse metadata and experiment files\n",
    "layers, N, q_min, q_max = parse_metadata(set_dir)\n",
    "q = 10*np.linspace(q_min, q_max, N)\n",
    "exp_names = next(os.walk('experiments/' + sample_name))[1]\n",
    "exp_names = [sample_name + '/' + exp_names[j] for j in np.argsort([int(i[:i.index('K')]) for i in exp_names])]\n",
    "\n",
    "print('set directory:', set_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f9e5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and process data\n",
    "x_data, x_orig, x_moms, y_data, y_columns, y_header, y_ids, y_labels, y_units = process_data(data_dir, sample_name,\n",
    "                                                                                             exp_names[0], q, seed)\n",
    "\n",
    "# standardize data\n",
    "scaler = StandardScaler().fit(y_data[:,np.array(y_ids[:-1])])\n",
    "y_data[:,np.array(y_ids[:-1])] = scaler.transform(y_data[:,np.array(y_ids[:-1])])\n",
    "\n",
    "# split data\n",
    "x_train, x_valid, x_test, y_train, y_valid, y_test = split_data(x_data, y_data, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c14be4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to torch tensors\n",
    "x_train = torch.from_numpy(x_train).unsqueeze(1)\n",
    "x_valid = torch.from_numpy(x_valid).unsqueeze(1)\n",
    "x_test = torch.from_numpy(x_test).unsqueeze(1)\n",
    "y_train = torch.from_numpy(y_train)\n",
    "y_valid = torch.from_numpy(y_valid)\n",
    "y_test = torch.from_numpy(y_test)\n",
    "\n",
    "height = x_train.size()[2]\n",
    "width = x_train.size()[3]\n",
    "num_features = len(y_ids) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b11306d",
   "metadata": {},
   "source": [
    "### Define model\n",
    "\n",
    "- Input the **model name** (vae, cvae, rvae) for the model to train according to:\n",
    "    * vae: simple VAE with no classifier or regressors\n",
    "    * cvae: VAE + classifier\n",
    "    * rvae: CVAE + regressors for each parameter value\n",
    "\n",
    "\n",
    "- Input the **model number** to resume training (or to continue analysis without further fitting), or -1 to start a new fit.\n",
    "\n",
    "\n",
    "- Input the number of models (**reps**) to train in succession, and set the **batch size** and number of **epochs**.\n",
    "\n",
    "\n",
    "- Set **z_std_norm** to False if z_mean is presumed to match the parameter values, or True if presumed to be 0, and set the parameters defining the model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298d179e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model to train\n",
    "model_name = 'cvae'\n",
    "model_num = -1           # -1 to start a new fit, model number to resume\n",
    "\n",
    "# training parameters\n",
    "reps = 1\n",
    "batch_size = 256\n",
    "epochs = 120\n",
    "\n",
    "# model parameters\n",
    "z_std_norm = False       # True if z ~ N(0,1), False if z ~ N(mu,1), mu > 0\n",
    "kwargs = {\n",
    "    'hidden_dim': 256,\n",
    "    'latent_dim': num_features,\n",
    "    'start_filters': 8,\n",
    "    'kernel_size': 7,\n",
    "    'pool_size': 4,\n",
    "    'num_conv': 2,\n",
    "    'num_dense': 5,\n",
    "    'slope': 0.3,\n",
    "    'drop': False,\n",
    "    'beta_1': 0.01,\n",
    "    'beta_2': 10.\n",
    "}\n",
    "\n",
    "device = torch.device(\"cuda:6\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54351b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model directories\n",
    "model_prefix = '/' + model_name + '_'\n",
    "resume_fit = model_num >= 0\n",
    "\n",
    "if resume_fit:\n",
    "    # load args from saved model directory\n",
    "    model_dir = set_dir + model_prefix + str(model_num)\n",
    "    args = torch.load(model_dir + '/model_0/model.torch')['args']\n",
    "    start_epoch = args['epochs']\n",
    "    epochs = start_epoch + epochs\n",
    "    args['epochs'] = epochs\n",
    "    \n",
    "    kwargs = args['kwargs']\n",
    "    \n",
    "else:\n",
    "    # create new model directory\n",
    "    args = {}\n",
    "    dirs = next(os.walk(set_dir))[1]\n",
    "    for k in dirs:\n",
    "        if k.startswith('.'): dirs.remove(k)\n",
    "    dirs.remove('data')\n",
    "    if 'properties' in dirs: dirs.remove('properties')\n",
    "\n",
    "    if len(dirs):\n",
    "        idns = [int(d.split('_')[-1]) for d in dirs]\n",
    "        idn = max(idns) + 1\n",
    "        args['model_num'] = idn\n",
    "        model_dir = set_dir + model_prefix + str(idn)\n",
    "    else:\n",
    "        args['model_num'] = 0\n",
    "        model_dir = set_dir + model_prefix + '0'\n",
    "\n",
    "    os.makedirs(model_dir)\n",
    "    start_epoch = 0\n",
    "    \n",
    "    # save arguments\n",
    "    args['batch_size'] = batch_size\n",
    "    args['reps'] = reps\n",
    "    args['epochs'] = epochs\n",
    "    args['z_std_norm'] = z_std_norm\n",
    "    args['kwargs'] = kwargs\n",
    "\n",
    "meta = json.dumps(args, sort_keys=True, indent=2)\n",
    "with open(model_dir + '/args.txt', 'w') as f:\n",
    "    f.write(meta)\n",
    "\n",
    "print('model directory:', model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d13122f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure data loaders\n",
    "data_train = TensorDataset(x_train, y_train)\n",
    "data_valid = TensorDataset(x_valid, y_valid)\n",
    "data_test = TensorDataset(x_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(data_train, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(data_valid, batch_size=batch_size)\n",
    "test_loader = DataLoader(data_test, batch_size=batch_size)\n",
    "\n",
    "d_sets = ['train', 'valid', 'test']\n",
    "data_loaders = dict(zip(d_sets, [DataLoader(data_train, batch_size=batch_size), valid_loader, test_loader]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dca719c",
   "metadata": {},
   "source": [
    "### Train model\n",
    "\n",
    "- Train reps number of models in succession."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d98586",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for r in range(reps):\n",
    "    image_dir = model_dir + '/model_' + str(r)\n",
    "    if not os.path.exists(image_dir): os.makedirs(image_dir)\n",
    "\n",
    "    model, opt, metric_keys = init_model(model_name, height, width, num_features, kwargs, device)\n",
    "    if r == 0: print(model)\n",
    "\n",
    "    print('====== repetition:', r)\n",
    "\n",
    "    if resume_fit:\n",
    "        model.load_state_dict(torch.load(image_dir + '/model.torch')['state'])\n",
    "        opt.load_state_dict(torch.load(image_dir + '/model.torch')['optimizer'])\n",
    "        dynamics = torch.load(image_dir + '/model.torch')['dynamics']\n",
    "    else: dynamics = []\n",
    "\n",
    "    for epoch in range(start_epoch + 1, epochs + 1):\n",
    "        train_metrics = train(epoch, model, opt, metric_keys, train_loader, device, model_name, z_std_norm, y_ids) \n",
    "        valid_metrics = evaluate(epoch, model, metric_keys, train_loader, device, model_name, z_std_norm, y_ids)\n",
    "        dynamics.append({\n",
    "            'epoch': epoch,\n",
    "            'train': train_metrics,\n",
    "            'valid': valid_metrics\n",
    "        })\n",
    "\n",
    "    results = {\n",
    "        'args': args,\n",
    "        'dynamics': dynamics,\n",
    "        'state': model.state_dict(),\n",
    "        'optimizer': opt.state_dict()\n",
    "    }\n",
    "\n",
    "    # save data and metadata to .torch dictionary\n",
    "    with open(image_dir + '/model.torch', 'wb') as f:\n",
    "        torch.save(results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa85ce0d",
   "metadata": {},
   "source": [
    "### Evaluate a representative model\n",
    "\n",
    "- Input the **repetition** to load the corresponding trained model.\n",
    "\n",
    "\n",
    "- Load and process the experimental data.\n",
    "\n",
    "\n",
    "- Plot the training history.\n",
    "\n",
    "\n",
    "- Make predictions on all synthetic and experimental data.\n",
    "\n",
    "\n",
    "- Plot example reconstructions of synthetic data in each error quartile, and reconstructions of experimental data.\n",
    "\n",
    "\n",
    "- Visualize the latent space according to y-values along 2 dimensions.\n",
    "\n",
    "\n",
    "- Plot performance of regressors, if present.\n",
    "\n",
    "\n",
    "- Find the optimal threshold for classifier and plot classifier performance, if present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f278fa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# repetition to evaluate\n",
    "r = 0\n",
    "image_dir = model_dir + '/model_' + str(r)\n",
    "model, _, _ = init_model(model_name, height, width, num_features, kwargs, device)\n",
    "model.load_state_dict(torch.load(image_dir + '/model.torch')['state'])\n",
    "\n",
    "# process experiment\n",
    "x_exp = process_exp(exp_names, q, x_moms)\n",
    "x_exp = torch.from_numpy(x_exp).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3bd9ef",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot training history\n",
    "dynamics = torch.load(image_dir + '/model.torch')['dynamics']\n",
    "plot_history(image_dir, dynamics, logscale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d01bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on synthetic data\n",
    "df = get_predictions(model, data_loaders, d_sets, device, height, width, num_features, kwargs, model_name, z_std_norm,\n",
    "                     y_ids, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfb73b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on experimental data\n",
    "df_exp = get_predictions_exp(model, x_exp, exp_names, device, height, width, num_features, kwargs, model_name,\n",
    "                             z_std_norm, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6600e8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print predictions of i_th experiment\n",
    "i = 0\n",
    "print('experiment:', exp_names[i])\n",
    "if model_name == 'rvae':\n",
    "    dict_exp = dict(zip(y_header + ['class'], df_exp.iloc[i]['y_pred']))\n",
    "    print(dict_exp)\n",
    "    \n",
    "elif model_name == 'cvae':\n",
    "    dict_exp = dict(zip(y_header, df_exp.iloc[i]['z']))\n",
    "    dict_exp['class_prox'] = df_exp.iloc[i]['y_pred'][0]\n",
    "    print(dict_exp)\n",
    "\n",
    "else:\n",
    "    if not z_std_norm:\n",
    "        dict_exp = dict(zip(y_header, df_exp.iloc[i]['z']))\n",
    "        print(dict_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975b4b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot example reconstructions (training)\n",
    "plot_decoded(image_dir, np.stack(df.loc[df['set']=='train', 'x_pred'].values),\n",
    "             np.stack(df.loc[df['set']=='train', 'x_true'].values),\n",
    "             np.stack(df.loc[df['set']=='train', 'x_mse'].values), 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a78072e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot example reconstructions (validation)\n",
    "plot_decoded(image_dir, np.stack(df.loc[df['set']=='valid', 'x_pred'].values),\n",
    "             np.stack(df.loc[df['set']=='valid', 'x_true'].values),\n",
    "             np.stack(df.loc[df['set']=='valid', 'x_mse'].values), 'valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e06bd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot example reconstructions (testing)\n",
    "plot_decoded(image_dir, np.stack(df.loc[df['set']=='test', 'x_pred'].values),\n",
    "             np.stack(df.loc[df['set']=='test', 'x_true'].values),\n",
    "             np.stack(df.loc[df['set']=='test', 'x_mse'].values), 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d185ddb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot reconstructed experiment\n",
    "plot_decoded_exp(image_dir, np.stack(df_exp['x_pred'].values), exp_names, q, x_moms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487f17ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize separability of latent space (training)\n",
    "plot_latent_representation(image_dir, np.stack(df.loc[df['set']=='train', 'z'].values),\n",
    "                           np.stack(df.loc[df['set']=='train', 'y_true'].values),\n",
    "                           y_ids, y_labels, y_units, 'encoded_train', np.stack(df_exp['z'].values), exp_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f66e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize separability of latent space (validation)\n",
    "plot_latent_representation(image_dir, np.stack(df.loc[df['set']=='valid', 'z'].values),\n",
    "                           np.stack(df.loc[df['set']=='valid', 'y_true'].values),\n",
    "                           y_ids, y_labels, y_units, 'encoded_valid', np.stack(df_exp['z'].values), exp_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a5e47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize separability of latent space (testing)\n",
    "plot_latent_representation(image_dir, np.stack(df.loc[df['set']=='test', 'z'].values),\n",
    "                           np.stack(df.loc[df['set']=='test', 'y_true'].values),\n",
    "                           y_ids, y_labels, y_units, 'encoded_test', np.stack(df_exp['z'].values), exp_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502dba1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot regressor performance\n",
    "if (model_name == 'rvae') or ((model_name == 'cvae') and (not z_std_norm)):\n",
    "    plot_predicted(image_dir, dict(zip(d_sets, [np.stack(df.loc[df['set'] == k, 'z'].values) for k in d_sets])),\n",
    "                   dict(zip(d_sets, [np.stack(df.loc[df['set'] == k, 'y_true'].values) for k in d_sets])),\n",
    "                   y_ids, y_labels, y_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78e0f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find optimal threshold and plot classifier performance\n",
    "if (model_name == 'rvae') or (model_name == 'cvae'):\n",
    "    fpr, tpr, roc_auc, th = get_roc(df, d_sets)\n",
    "    tpr0, fpr0, th = get_optimal_threshold(fpr[1], tpr[1], th[1])\n",
    "\n",
    "    plot_roc(image_dir, fpr, tpr, roc_auc, [tpr0, fpr0, th])\n",
    "    plot_precision_recall_f1(image_dir, df, d_sets, th)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b87b32b",
   "metadata": {},
   "source": [
    "### Other\n",
    "\n",
    "- For rvae model only, invert the weight matrix mapping z to the parameter values, which can be used to input known parameter values to get z and then decode spectrum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d777ffb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get reflectivity given input parameters (rvae only)\n",
    "if model_name == 'rvae':\n",
    "    U = np.zeros((num_features, num_features))\n",
    "    for i in range(num_features):\n",
    "        U[i,:] = getattr(model, \"reg_%d\"%i).weight.detach().cpu()\n",
    "    _U = np.linalg.inv(U)\n",
    "\n",
    "    z_example = np.dot(_U, y_test[0, y_ids[:-1]].numpy())\n",
    "    z_example = torch.from_numpy(z_example).unsqueeze(0).to(device)\n",
    "    x_example = model.decode(z_example).squeeze().detach().cpu().numpy()\n",
    "\n",
    "    prop.set_size(18)\n",
    "    lprop = prop.copy()\n",
    "    lprop.set_size(14)\n",
    "    fig, ax = plt.subplots(figsize=(5.5,5))\n",
    "    ax.plot(q, normalize_log_inverse(x_example[:,0], x_moms), color='#316986', label='R$^{++}$')\n",
    "    ax.plot(q, normalize_log_inverse(x_example[:,1], x_moms), color='#C86646', label='R$^{--}$')\n",
    "    ax.set_yscale('log')\n",
    "    format_axis(ax, 'Q (nm$^{-1}$)', 'Reflectivity', prop)\n",
    "    ax.legend(prop=lprop, edgecolor='white', framealpha=1, loc='upper right');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117615e8",
   "metadata": {},
   "source": [
    "### Evaluate all models\n",
    "\n",
    "- Compile the training history and experiment predictions on all model repetitions.\n",
    "\n",
    "\n",
    "- Plot the training history statistics.\n",
    "\n",
    "\n",
    "- Plot classification statistics on experimental data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d63d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on all models to compute statistics\n",
    "dynamics, ths = [], []\n",
    "for r in range(reps):\n",
    "    image_dir = model_dir + '/model_' + str(r)\n",
    "    model, _, _ = init_model(model_name, height, width, num_features, kwargs, device)\n",
    "    model.load_state_dict(torch.load(image_dir + '/model.torch')['state'])\n",
    "    \n",
    "    # plot training history\n",
    "    dynamics += [torch.load(image_dir + '/model.torch')['dynamics']]\n",
    "    \n",
    "    # predict on synthetic data\n",
    "    df = get_predictions(model, data_loaders, d_sets, device, height, width, num_features, kwargs, model_name,\n",
    "                         z_std_norm, y_ids, scaler)\n",
    "    \n",
    "    # get optimal threshold\n",
    "    if (model_name == 'rvae') or (model_name == 'cvae'):\n",
    "        fpr, tpr, _, th = get_roc(df, d_sets)\n",
    "        _, _, th = get_optimal_threshold(fpr[1], tpr[1], th[1])\n",
    "        ths += [th]\n",
    "        \n",
    "    # predict on experimental data\n",
    "    if r > 0:\n",
    "        df = get_predictions_exp(model, x_exp, exp_names, device, height, width, num_features, kwargs, model_name,\n",
    "                                 z_std_norm, scaler)\n",
    "        df['model'] = r\n",
    "        df['th'] = th\n",
    "        df_exp = df_exp.append(df, ignore_index=True)\n",
    "    else:\n",
    "        df_exp = get_predictions_exp(model, x_exp, exp_names, device, height, width, num_features, kwargs, model_name,\n",
    "                                     z_std_norm, scaler)\n",
    "        df_exp['model'] = r\n",
    "        df_exp['th'] = th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfad10d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot training history statistics\n",
    "plot_history_statistics(model_dir, dynamics, logscale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd5519e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot class statistics on experimental sample\n",
    "plot_class_exp_statistics(df_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb6648b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
